1 hadoop安装
    1.1 解压hadoop文件，文件为绿色版，解压后可以直接使用。
    1.2 配置环境变量vim  /etc/profile中插入变量
		#大数据用hasoop环境变量
		export HADOOP_NAME=/home/tom/hadoop-3.1.2（hadoop文件的安装目录）
		export PATH=$PATH:$HADOOP_NAME/bin:$HADOOP_NAME/sbin（bin的作用sbin的作用）
	  
    1.3 使环境变量生效，使用 hadoop version 检测是否配置成功
		(前提，已经执行 命令 source /etc/profile)
		（或者在 /root/.bashrc文件中写入  source /etc/profile）
	
    2 检查防火墙是否运行 	sudo ufw status
		urw enable	在系统启动时启动防火墙
		urw disable	在系统启动时关闭防火墙

    3.检查主机名，修改主机名为一个短小的名字vim /etc/hostname 编辑模式下修改原来命名为想改的名字
：wq！保存退出 reboot重启即可生效
	非root权限下操作相同
    4.ssh免密登录
 由于在主节点和从节点之间通信是，hadoop使用的是ssh通信协议，保证数据传输的安全性，但是每次主从节点通信时不能每次都输入用户名和密码，太过于麻烦，所以我们要为主从节点之间设置免密的ssh登录，这种登录方式每次登录都会生成一个密钥，非常的复杂，破解难度极大，我们的方式是通过密钥生成在服务器上，然后把它复制保存到每次节点登录都会调用的一个文件下，这样就在通信时默认调用该文件里的密钥
   （1）切换root
    （2）ssh-keygen -t rsa 查看密钥，是一个图形
     （3）cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys 把ssh文件夹下的密钥复制到另一个文件下
      （4）ssh.localhost 验证登录
        (5)cd ~/.ssh ls -l 查看当前的ssh目录下的文件
        （6）cat id_rsa.pub 查看该文件中是否有复制来的密钥